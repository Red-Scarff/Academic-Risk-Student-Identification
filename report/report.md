# 模式识别实验报告

## 问题定义描述

本实验旨在利用学生在学习平台前几周的匿名行为数据（如课程视频观看时长、论坛发帖数、测验尝试次数等），构建并对比不同分类模型，以识别可能存在学业困难（课程不及格、辍学）的学生。“学业困难” 的评估标准自行定义，本实验中以 “不及格” 和 “辍学” 作为判定依据，在后续报告中详细。

## 数据集介绍

### 数据集来源与结构

采用 Open University Learning Analytics Dataset（OULAD）

数据集覆盖 22 门课程、32593 名学生，包含学生评估结果及与 VLE 的互动日志（共 10655280 行点击行为记录）。课程开始时间分为 2 月（标记 “B”）和 10 月（标记 “J”）。数据通过唯一标识符关联各表，整合后形成包含人口统计特征、学习行为特征、评估表现等多维度的数据集。

主要特征包括：
人口统计：性别、地区、最高教育水平、年龄段、是否有残疾等；
学习行为：VLE 平台点击次数、活跃天数、日均参与度、测验尝试次数等；
课程信息：课程模块、开课年份、学期等；
成绩相关：最终成绩、评估得分等。

该数据集包含 6 个文件：

- courses.csv：课程基本信息（如课程代码、开始月份等）；
- assessments.csv：评估考试相关信息（如评估类型、权重等）；
- studentAssessment.csv：学生评估结果分析；
- studentInfo.csv：学生个人信息（如性别、地区、最高教育水平）及课程最终成绩；
- studentRegistration.csv：学生课程注册情况；
- studentvle.csv：学生在虚拟学习环境（VLE）中的行为数据（如点击次数、活跃天数等）；
- vle.csv：在线平台交互信息。

## 算法原理介绍

1. 逻辑回归（Logistic Regression）

- 核心原理：基于线性模型，通过 Sigmoid 函数将特征线性组合映射为概率值（范围 [0,1]），用于二分类任务。模型假设特征与目标变量之间存在线性关系，通过极大似然估计求解权重参数，使样本属于正类的概率最大化。

- 关键特性：可解释性强，权重系数直接反映特征对分类的影响方向与相对重要性；计算效率高，适合中小规模数据集；对线性关系建模能力强，但难以捕捉复杂非线性模式。

2. 随机森林（Random Forest）

- 核心原理：集成学习方法，由多棵决策树通过 Bagging 采样和特征随机选择构建。每棵树基于基尼不纯度或信息增益分裂节点，最终通过多数投票确定分类结果。其核心思想是通过 “集体决策” 降低单一决策树的方差，提升模型泛化能力。

- 关键特性：能自动处理特征交互，对非线性关系和复杂模式建模能力强；可自然输出特征重要性评估，抗噪声和过拟合能力强；计算复杂度随树的数量增加而上升，但并行化能力好。

3. ...

(TODO其他待完成模型)

## 实验设置

流程图：
![alt text](flowchart.png)

0. 数据预处理

数据存在缺失值（如部分学生行为数据不全）、分类变量（需编码处理）及潜在的不平衡分布（学业困难学生比例）。实验聚焦于前 4 周的行为数据，需通过数据合并、特征筛选与标准化等操作构建可用数据集。

<center>
<img src="image-3.png" width="500"/>
</center>

1. 逻辑回归

使用GridSearch优化正则化参数
```
param_grid = {
    'C': [0.001, 0.01, 0.1, 1, 10, 100],
    'penalty': ['l1', 'l2']
}
```
​​最终确定最优参数为，网格搜索优化正则化强度（C=10）和惩罚类型（L1正则化），通过交叉验证平衡模型复杂度与过拟合风险，选用liblinear求解器确保高效处理高维特征。最终输出评估指标值，并输出roc曲线和shap分析图。

2. 随机森林

使用固定参数
```
rf_params = {
    'n_estimators': 150,
    'max_depth': 10,
    'min_samples_split': 5,
    'class_weight': 'balanced'
}
```
​基于经验设置150棵子树与深度限制10层，搭配最小分裂样本数5和类别平衡权重，在保证决策多样性的同时控制模型复杂度，这种配置在计算效率与预测精度间取得最佳平衡。最终输出评估指标值，并输出roc曲线和shap分析图。

ps：随机森林与逻辑回归共用部分函数，实现于代码utils.py中。

3. ...

(TODO其他模型参数设置)

## 评估标准

- 准确率（Accuracy）：正确分类的样本占总样本的比例，适用于类别平衡场景；
- 精确率（Precision）：预测为正类的样本中实际为正类的比例，衡量 “查准率”；
- 召回率（Recall）：实际为正类的样本中被正确预测的比例，衡量 “查全率”；
- F1 分数：精确率与召回率的调和平均，综合评估模型对正负类的分类能力；
- AUC（Area Under ROC Curve）：ROC 曲线下面积，反映模型对正负样本的排序能力，适用于不平衡数据；
- 训练时间：体现计算效率。

## 实验结果与对比分析

### 数据处理

数据处理前后特征值对比：

<center class="half">
<img src="extreme_values_before.png" width="250"/>
<img src="extreme_values_after.png" width="250"/>
</center>

### 逻辑回归

</center>
<center class="half">
<img src="image-1.png" width="310"/>
<img src="roc_curve.png" width="240"/>
</center>
<center class="half">
<img src="feature_importance.png" width="350"/>
<img src="shap_summary.png" width="200"/>
</center>

在准确性方面，逻辑回归表现出基础但可靠的预测能力，其线性特性使模型在特征空间线性可分区域表现稳定，但在复杂决策边界处准确率受限。

特征敏感度呈现明显选择性，对"首页活跃天数"等少数核心特征高度敏感，这种特性使其在关键行为指标清晰时表现良好，但难以捕捉多维特征的交互效应。

参数调整相对直观，通过正则化系数即可平衡偏差-方差，但模型鲁棒性较弱，对特征相关性和异常值敏感。

可解释性是其核心优势，特征系数直接量化行为影响，为教育者提供明确干预方向。

然而在处理高度不平衡数据时，即使采用SMOTE采样，其刚性决策边界仍导致困难学生识别存在局限，特别是对行为模式模糊的边界案例识别不足。

### 随机森林

<center class="half">
<img src="image-2.png" width="310"/>
<img src="roc_curve-1.png" width="240"/>
</center>
<center class="half">
<img src="feature_importance-1.png" width="350"/>
<img src="shap_bar-1.png" width="200"/>
</center>

随机森林在准确性维度展现显著优势，其集成特性通过多角度特征抽样构建了鲁棒的决策体系，对困难学生的识别精度提升明显。

特征敏感度呈现智能平衡，既关注核心指标如"首页活跃度"，又能捕捉"早期参与度"与"退课时间"等特征的协同效应，这种多维感知能力使其适应复杂行为模式。

参数调整虽涉及更多超参数，但模型对参数变化容忍度高，鲁棒性强，对噪声数据和特征相关性不敏感。

计算效率突出，并行训练使其处理高维数据时仍保持高效。

可解释性相较逻辑回归较模糊，通过SHAP值实现，以揭示非线性关系。

在类别不平衡问题上，其自助采样机制天然适应数据分布，配合SMOTE后对困难学生的识别灵敏度达92%以上，成为教育预警系统的理想选择。

### ...

(TODO剩余的几个模型)

## 结论

(TODO完成所有模型后总结)

## 展望

(TODO)





# 附录：个人贡献声明

## 王赫 22336225

### 主要任务

- 完成了数据预处理；
- 负责逻辑回归和随机森林两大核心模型的开发与调优工作；
- 完成模型的性能评估与对比分析；
- 完成数据预处理，逻辑回归，随机森林部分的实验报告；

### 具体贡献

完成了数据预处理，先填补缺失值，进行数据清理，再设计好特征工程进行特征衍生，之后再通过维度压缩选择核心特征，最终使用smote技术处理训练集使正例负例达到平衡处理。

完成了逻辑回归模型和随机森林模型的构建，且逻辑回归使用gridsearch方法自动优化参数。除了常规的评估指标外，输出roc曲线和shap特征分析图，以对训练效果和模型特征进行可视化分析，提高模型对于特征的可解释性。

最后完成实验报告，对问题定义，数据集，评估指标等的描述。并分析了逻辑回归和随机森林的准确性，可解释性，鲁棒性等。

### 挑战与解决方案

实现shap特征分析时遇到维度报错`ValueError: Per-column arrays must each be 1-dimensional`，这个错误发生在创建DataFrame的时候，原因是在创建DataFrame时传入的数组不是一维的，即创建SHAP特征重要性的DataFrame时，mean_abs_shap数组的维度不正确。

之后通过以下修改方案解决问题：如果SHAP值数组是多维的，它会自动展平；如果特征数量不匹配，它会自动截断到最小长度，确保DataFrame能正确创建。

### 心得体会

通过本次学业困难学生识别系统的开发实践，我深刻认识到教育数据分析的独特挑战与价值。在构建逻辑回归和随机森林模型的过程中，我体会到特征工程的质量往往比算法选择更为关键——特别是创新性的early_engagement_score特征，通过融合前四周的关键行为指标，显著提升了模型对早期风险信号的捕捉能力。这种将教育理论与数据特征相融合的实践，让我领悟到技术方案必须服务于教育规律的本质要求。

在模型优化与评估阶段，两种算法的对比启示我辩证看待技术方案的适用边界：逻辑回归的可解释性为教育干预提供清晰指引，而随机森林的高精度则更适合构建预警系统。这些经验表明在未来教育科技项目中，需兼顾技术可行性、教育价值。

## 姓名 学号
...
