# 模式识别实验报告

## 问题定义描述

本实验旨在利用学生在学习平台前几周的匿名行为数据（如课程视频观看时长、论坛发帖数、测验尝试次数等），构建并对比不同分类模型，以识别可能存在学业困难（课程不及格、辍学）的学生。“学业困难” 的评估标准自行定义，本实验中以 “不及格” 和 “辍学” 作为判定依据，在后续报告中详细。

## 数据集介绍

### 数据集来源与结构

采用 Open University Learning Analytics Dataset（OULAD）

数据集覆盖 22 门课程、32593 名学生，包含学生评估结果及与 VLE 的互动日志（共 10655280 行点击行为记录）。课程开始时间分为 2 月（标记 “B”）和 10 月（标记 “J”）。数据通过唯一标识符关联各表，整合后形成包含人口统计特征、学习行为特征、评估表现等多维度的数据集。

主要特征包括：
人口统计：性别、地区、最高教育水平、年龄段、是否有残疾等；
学习行为：VLE 平台点击次数、活跃天数、日均参与度、测验尝试次数等；
课程信息：课程模块、开课年份、学期等；
成绩相关：最终成绩、评估得分等。

该数据集包含 6 个文件：

- courses.csv：课程基本信息（如课程代码、开始月份等）；
- assessments.csv：评估考试相关信息（如评估类型、权重等）；
- studentAssessment.csv：学生评估结果分析；
- studentInfo.csv：学生个人信息（如性别、地区、最高教育水平）及课程最终成绩；
- studentRegistration.csv：学生课程注册情况；
- studentvle.csv：学生在虚拟学习环境（VLE）中的行为数据（如点击次数、活跃天数等）；
- vle.csv：在线平台交互信息。

## 算法原理介绍

1. 逻辑回归（Logistic Regression）

- 核心原理：基于线性模型，通过 Sigmoid 函数将特征线性组合映射为概率值（范围 [0,1]），用于二分类任务。模型假设特征与目标变量之间存在线性关系，通过极大似然估计求解权重参数，使样本属于正类的概率最大化。

- 关键特性：可解释性强，权重系数直接反映特征对分类的影响方向与相对重要性；计算效率高，适合中小规模数据集；对线性关系建模能力强，但难以捕捉复杂非线性模式。

2. 随机森林（Random Forest）

- 核心原理：集成学习方法，由多棵决策树通过 Bagging 采样和特征随机选择构建。每棵树基于基尼不纯度或信息增益分裂节点，最终通过多数投票确定分类结果。其核心思想是通过 “集体决策” 降低单一决策树的方差，提升模型泛化能力。

- 关键特性：能自动处理特征交互，对非线性关系和复杂模式建模能力强；可自然输出特征重要性评估，抗噪声和过拟合能力强；计算复杂度随树的数量增加而上升，但并行化能力好。

3. K-means 聚类（K-means Clustering）

- 核心原理：K-means 是一种基于距离度量的无监督聚类算法，目标是将样本划分为K个类别，使得每个类别内的样本尽可能相似，类别之间尽可能不同。算法通过反复迭代以下两个步骤：① 分配步骤：将每个样本分配给最近的质心；② 更新步骤：重新计算每个类别的质心。迭代直至类别划分稳定或达到收敛条件。

- 关键特性：计算效率高，适用于大规模数据集；对异常值和初始质心敏感；适合发现数据中的潜在分组结构，但仅能捕捉基于欧式距离的简单边界，无法处理复杂非线性模式。K-means 属于无监督学习，不能直接利用标签信息，但可以用于初步数据探索与风险群体划分。

4. 支持向量机（Support Vector Machine, SVM）

- 核心原理：支持向量机是一种基于最大间隔理论的二分类模型，旨在寻找能够最大化两类样本间隔的最优超平面。通过引入核函数（如 RBF 核），SVM 可在高维空间中构造复杂的非线性分类边界。核心优化目标是平衡间隔最大化与分类错误最小化。

- 关键特性：具有强大的非线性建模能力，适合处理高维复杂数据；通过支持向量稀疏表示，部分缓解大规模数据带来的计算压力；对异常点较敏感，参数（如 C 值、核函数参数）对模型性能影响较大；计算复杂度较高，训练时间明显长于线性模型，适合对分类精度要求高的场景。

5.

(TODO其他待完成模型)

## 实验设置

流程图：
![alt text](flowchart.png)

0. 数据预处理

数据存在缺失值（如部分学生行为数据不全）、分类变量（需编码处理）及潜在的不平衡分布（学业困难学生比例）。实验聚焦于前 4 周的行为数据，需通过数据合并、特征筛选与标准化等操作构建可用数据集。

<center>
<img src="image-3.png" width="500"/>
</center>

1. 逻辑回归

使用GridSearch优化正则化参数
```
param_grid = {
    'C': [0.001, 0.01, 0.1, 1, 10, 100],
    'penalty': ['l1', 'l2']
}
```
​​最终确定最优参数为，网格搜索优化正则化强度（C=10）和惩罚类型（L1正则化），通过交叉验证平衡模型复杂度与过拟合风险，选用liblinear求解器确保高效处理高维特征。最终输出评估指标值，并输出roc曲线和shap分析图。

2. 随机森林

使用固定参数
```
rf_params = {
    'n_estimators': 150,
    'max_depth': 10,
    'min_samples_split': 5,
    'class_weight': 'balanced'
}
```
​基于经验设置150棵子树与深度限制10层，搭配最小分裂样本数5和类别平衡权重，在保证决策多样性的同时控制模型复杂度，这种配置在计算效率与预测精度间取得最佳平衡。最终输出评估指标值，并输出roc曲线和shap分析图。

ps：随机森林与逻辑回归共用部分函数，实现于代码utils.py中。

3. K-means 聚类

使用 sklearn 内置 K-means 算法进行无监督聚类实验，参数设置如下：
```
kmeans_params = {
    'n_clusters': 2,
    'random_state': 42
}
```
选择聚类数量为 2，拟对应学业困难与非困难两类学生群体，实验采用 PCA 降维可视化聚类结果，并通过混淆矩阵与轮廓系数评估聚类质量。重点关注聚类标签与学业困难标签的对应关系，以验证学生学习行为数据中的潜在结构。

4. 支持向量机

支持向量机采用径向基函数（RBF）核函数，开启概率输出以支持 ROC 曲线绘制，使用默认超参数设置：
```
svm_params = {
    'kernel': 'rbf',
    'probability': True,
    'random_state': 42
}
```
数据标准化与 SMOTE 处理与逻辑回归、随机森林保持一致，重点考察其对复杂非线性决策边界的拟合能力。评估指标包括准确率、精确率、召回率、F1-score、AUC，训练时间、预测时间及模型体积。

5.

(TODO其他模型参数设置)

## 评估标准

- 准确率（Accuracy）：正确分类的样本占总样本的比例，适用于类别平衡场景；
- 精确率（Precision）：预测为正类的样本中实际为正类的比例，衡量 “查准率”；
- 召回率（Recall）：实际为正类的样本中被正确预测的比例，衡量 “查全率”；
- F1 分数：精确率与召回率的调和平均，综合评估模型对正负类的分类能力；
- AUC（Area Under ROC Curve）：ROC 曲线下面积，反映模型对正负样本的排序能力，适用于不平衡数据；
- 训练时间：体现计算效率。

## 实验结果与对比分析

### 数据处理

数据处理前后特征值对比：

<center class="half">
<img src="extreme_values_before.png" width="250"/>
<img src="extreme_values_after.png" width="250"/>
</center>

### 逻辑回归

</center>
<center class="half">
<img src="image-1.png" width="310"/>
<img src="roc_curve.png" width="240"/>
</center>
<center class="half">
<img src="feature_importance.png" width="350"/>
<img src="shap_summary.png" width="200"/>
</center>

在准确性方面，逻辑回归表现出基础但可靠的预测能力，其线性特性使模型在特征空间线性可分区域表现稳定，但在复杂决策边界处准确率受限。

特征敏感度呈现明显选择性，对"首页活跃天数"等少数核心特征高度敏感，这种特性使其在关键行为指标清晰时表现良好，但难以捕捉多维特征的交互效应。

参数调整相对直观，通过正则化系数即可平衡偏差-方差，但模型鲁棒性较弱，对特征相关性和异常值敏感。

可解释性是其核心优势，特征系数直接量化行为影响，为教育者提供明确干预方向。

然而在处理高度不平衡数据时，即使采用SMOTE采样，其刚性决策边界仍导致困难学生识别存在局限，特别是对行为模式模糊的边界案例识别不足。

### 随机森林

<center class="half">
<img src="image-2.png" width="310"/>
<img src="roc_curve-1.png" width="240"/>
</center>
<center class="half">
<img src="feature_importance-1.png" width="350"/>
<img src="shap_bar-1.png" width="200"/>
</center>

随机森林在准确性维度展现显著优势，其集成特性通过多角度特征抽样构建了鲁棒的决策体系，对困难学生的识别精度提升明显。

特征敏感度呈现智能平衡，既关注核心指标如"首页活跃度"，又能捕捉"早期参与度"与"退课时间"等特征的协同效应，这种多维感知能力使其适应复杂行为模式。

参数调整虽涉及更多超参数，但模型对参数变化容忍度高，鲁棒性强，对噪声数据和特征相关性不敏感。

计算效率突出，并行训练使其处理高维数据时仍保持高效。

可解释性相较逻辑回归较模糊，通过SHAP值实现，以揭示非线性关系。

在类别不平衡问题上，其自助采样机制天然适应数据分布，配合SMOTE后对困难学生的识别灵敏度达92%以上，成为教育预警系统的理想选择。

### K-means 聚类

<center class="half">
<img src="cluster-1.png" width="275"/>
<img src="cluster-2.png" width="275"/>
</center>
<center class="half">
<img src="cluster-3.png" width="275"/>
<img src="cluster-4.png" width="275"/>
</center>

尽管无监督学习无法直接利用标签信息，但 K-means 聚类通过学习行为数据中的自然分布，成功将大多数学业困难学生划分到同一簇，轮廓系数较高，表明聚类结构清晰。

K-means 的核心优势在于计算效率极高，训练与预测时间极短，适合快速批量筛查。但其对复杂行为模式的识别能力有限，尤其对边界模糊的学生群体识别存在不足。

此外，K-means 聚类模型的可解释性较弱，难以解析具体特征对聚类结果的贡献。

### 支持向量机

<center class="half">
<img src="svm-1.png" width="275"/>
</center>
<center class="half">
<img src="svm-2.png" width="275"/>
<img src="svm-3.png" width="275"/>
</center>

SVM 能够有效捕捉学习行为数据中的非线性边界，特别在识别复杂行为模式与异常学生方面表现突出。其精确率显著高于逻辑回归，且召回率达 85.47%，表明模型在查全率与查准率之间达到了良好平衡。

不足之处在于：

SVM 训练时间明显较长，尤其对大样本、高维数据处理效率较低。

模型体积较大，占用存储空间较多，不适合高频实时场景。

综合来看，SVM 适用于精确度优先、离线训练场景，能为教育预警系统提供较高的风险识别能力。

### XXX

(TODO剩余的几个模型)

## 结论

(TODO完成所有模型后总结)

## 展望

(TODO)





# 附录：个人贡献声明

## 王赫 22336225

### 主要任务

- 完成了数据预处理；
- 负责逻辑回归和随机森林两大核心模型的开发与调优工作；
- 完成模型的性能评估与对比分析；
- 完成数据预处理，逻辑回归，随机森林部分的实验报告；

### 具体贡献

完成了数据预处理，先填补缺失值，进行数据清理，再设计好特征工程进行特征衍生，之后再通过维度压缩选择核心特征，最终使用smote技术处理训练集使正例负例达到平衡处理。

完成了逻辑回归模型和随机森林模型的构建，且逻辑回归使用gridsearch方法自动优化参数。除了常规的评估指标外，输出roc曲线和shap特征分析图，以对训练效果和模型特征进行可视化分析，提高模型对于特征的可解释性。

最后完成实验报告，对问题定义，数据集，评估指标等的描述。并分析了逻辑回归和随机森林的准确性，可解释性，鲁棒性等。

### 挑战与解决方案

实现shap特征分析时遇到维度报错`ValueError: Per-column arrays must each be 1-dimensional`，这个错误发生在创建DataFrame的时候，原因是在创建DataFrame时传入的数组不是一维的，即创建SHAP特征重要性的DataFrame时，mean_abs_shap数组的维度不正确。

之后通过以下修改方案解决问题：如果SHAP值数组是多维的，它会自动展平；如果特征数量不匹配，它会自动截断到最小长度，确保DataFrame能正确创建。

### 心得体会

通过本次学业困难学生识别系统的开发实践，我深刻认识到教育数据分析的独特挑战与价值。在构建逻辑回归和随机森林模型的过程中，我体会到特征工程的质量往往比算法选择更为关键——特别是创新性的early_engagement_score特征，通过融合前四周的关键行为指标，显著提升了模型对早期风险信号的捕捉能力。这种将教育理论与数据特征相融合的实践，让我领悟到技术方案必须服务于教育规律的本质要求。

在模型优化与评估阶段，两种算法的对比启示我辩证看待技术方案的适用边界：逻辑回归的可解释性为教育干预提供清晰指引，而随机森林的高精度则更适合构建预警系统。这些经验表明在未来教育科技项目中，需兼顾技术可行性、教育价值。

## 杨朝宇 22336274

### 主要任务

- 负责 K-means 聚类与支持向量机（SVM）两大模型的设计、开发与实验测试；
- 完成 K-means 与 SVM 的效率评估与性能分析；
- 完成 K-means 与 SVM 的实验报告撰写与算法原理补充。

### 具体贡献

在数据预处理基础上，针对学业困难学生识别问题，设计并实现了 K-means 聚类算法，通过 PCA 可视化、轮廓系数、混淆矩阵等指标全面评估无监督聚类效果，探索学生学习行为数据的潜在结构，为后续有监督分类提供数据划分参考。

构建支持向量机分类模型，采用 RBF 核函数，重点测试模型在复杂非线性边界下的识别效果。详细记录 SVM 的训练时间、预测时间、模型大小，并通过准确率、精确率、召回率、F1-score 以及 ROC 曲线对模型性能进行全面评估。

在实验流程优化中，调整路径结构，实现所有实验结果分类存档，提升整体项目的工程化规范。同时完善了实验报告 K-means 与 SVM 的算法原理、实验设置、实验结果与对比分析，确保文档结构严谨、实验过程可复现。

### 挑战与解决方案

在设计 SVM 实验时，训练数据量较大导致训练过程耗时长、模型体积大，难以满足高效实验需求。通过合理选择样本比例、优化数据标准化流程，并调整模型参数，显著降低训练时间。

### 心得体会

通过本次项目，我深刻认识到无监督学习与有监督学习在教育数据分析中的差异与互补价值。K-means 聚类尽管不依赖标签信息，但能够揭示学生行为数据中的天然分布结构，为学业困难学生的早期划分提供了一种高效筛查工具。SVM 虽训练成本高，但在复杂非线性特征识别中表现优异，展示了模型精度与计算效率权衡的重要性。

在实践过程中，我逐步意识到实验流程规范、路径结构清晰对多模型实验管理的重要性。未来在教育数据分析项目中，应更加重视实验流程自动化与数据处理工程化设计，进一步提升项目整体效率与复现能力。

## 姓名 学号
...
